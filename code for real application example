############################ Chunk 1 ############################
library(BGLR); library(MPS)

# setwd("Put you directory here")
setwd("~/Desktop/Paper2025GS/Example multi Env real data")
load("./data/Wheat_Durum.rdata")
ls()

# ID and phenotypes
GID <- Y$GID
Y <- Y[, grep("_Env3$", colnames(Y))]
id_remove <- unique(unlist(apply(Y, 2, function(x) which(is.na(x)))))
Y <- Y[-id_remove, ]
GID <- GID[-id_remove]
X <- X[-id_remove, ]

# Percentage of missing data by trait and environment
apply(Y, 2, function(x) sum(is.na(x))) / nrow(Y) * 100

# Reference distributions
q1 <- c(0.8, 0.1, 0.05, 0.025, 0.025)  # Para 5 categorías
q2 <- c(0.8, 0.1, 0.05, 0.05)          # Para 4 categorías

# to save csv
dir.create("csv")

# MCMC parameters
no_iter <- 10e3; no_burn <- 1e3; thin <- 2
id_samples <- which(seq(1, no_iter, thin) > no_burn)

############################ Chunk 2 ############################
sel_eval <- function(i, method = "kl"){
  n <- nrow(Y)
  nTst <- ceiling(n * 0.3)
  idTst <- sample(1:n, nTst, replace = FALSE)
  Yfinal <- Y
  Yfinal[idTst, ] <- NA
  
  name_folder <- paste0("out_rep_", i)
  dir.create(name_folder)
  
  ETA <- list(list(X = X, model='BRR', saveEffects = TRUE))
  
  for(j in 1:3){
    fit <- BGLR(
      y = Yfinal[, j],
      response_type = 'ordinal',
      ETA = ETA,
      nIter = no_iter,
      burnIn = no_burn,
      thin = thin,
      verbose = FALSE,
      saveAt = paste0("./", name_folder, "/trait_", j)
    )
  }
  
  B <- list()
  thresholds <- list()
  
  for(j in 1:3){
    
    beta_file <- paste0("./", name_folder, "/trait_", j, "ETA_1_b.bin")
    thr_file  <- paste0("./", name_folder, "/trait_", j, "thresholds.dat")
    
    B[[j]] <- readBinMat(beta_file)
    thresholds[[j]]  <- as.matrix(read.table(thr_file)[id_samples, ])
  }
  
  n_categories <- apply(Yfinal, 2, function(col) length(unique(col[!is.na(col)])))
  target <- lapply(n_categories, function(n) {
    if (n == 5) q1 else if (n == 4) q2 else stop("Número de categorías no soportado")
  })
  
  Xcand <- X[idTst,]
  
  out <- MultitraitOPS(Xcand = Xcand, B = B, thresholds = thresholds, target = target, method = "kl")
  
  idSel <- out$ranking %in% 1:30
  idRandomSampling <- sample(1:nTst, 30, replace = FALSE)
  
  Yreal <- Y[idTst,]
  Yrandom <- Yreal[idRandomSampling,]
  YSel <-  Yreal[idSel,]
  
  meanYrandom <- colMeans(Yrandom)
  meanYSel <- colMeans(YSel)
  
  meanYSel - meanYrandom
  
  # Calcular proporciones para cada columna
  aleatorio <- lapply(Yrandom, function(x) {
    tbl <- table(x)
    prop <- prop.table(tbl)
    data.frame(Level = names(prop), Count = as.numeric(tbl), Proportion = as.numeric(prop))
  })

  sel <- lapply(YSel, function(x) {
    tbl <- table(x)
    prop <- prop.table(tbl)
    data.frame(Level = names(prop), Count = as.numeric(tbl), Proportion = as.numeric(prop))
  })
  
  sel_df <- do.call(rbind, lapply(names(sel), function(trait) {
    df <- sel[[trait]]
    data.frame(
      method = "loss",
      trait = trait,
      level = df$Level,
      count = df$Count,
      proportion = df$Proportion,
      row.names = NULL
    )
  }))
  
  
  aleatorio_df <- do.call(rbind, lapply(names(aleatorio), function(trait) {
    df <- aleatorio[[trait]]
    data.frame(
      method = "random",
      trait = trait,
      level = df$Level,
      count = df$Count,
      proportion = df$Proportion,
      row.names = NULL
    )
  }))
  
  salida <- rbind.data.frame(sel_df, aleatorio_df)

  write.csv(salida, paste0("./csv/", "salida_iter_", i, ".csv"), row.names = FALSE)
  
  unlink(name_folder, recursive = TRUE)
  
}

